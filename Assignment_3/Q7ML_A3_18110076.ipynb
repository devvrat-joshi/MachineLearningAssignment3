{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q7ML-A3-18110076.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Colab Link (IITGN):\n",
        "https://colab.research.google.com/drive/14jnUU_AnAVP9V8UEYoxHFwsdrHrYqgEQ?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29hByVWNheij",
        "outputId": "2acb0127-7bf2-4eb2-ad03-4d7b1ce639a8"
      },
      "source": [
        "! git clone https://github.com/devvrat-joshi/datafiles\n",
        "! unzip \"/content/datafiles/dataset.zip\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'datafiles'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 9 (delta 1), reused 4 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (9/9), done.\n",
            "Archive:  /content/datafiles/dataset.zip\n",
            "   creating: images/\n",
            "  inflating: images/dogs0.jpg        \n",
            "  inflating: images/dogs1.jpg        \n",
            "  inflating: images/dogs10.jpg       \n",
            "  inflating: images/dogs11.jpg       \n",
            "  inflating: images/dogs12.jpg       \n",
            "  inflating: images/dogs13.jpg       \n",
            "  inflating: images/dogs14.jpg       \n",
            "  inflating: images/dogs15.jpg       \n",
            "  inflating: images/dogs16.jpg       \n",
            "  inflating: images/dogs17.jpg       \n",
            "  inflating: images/dogs18.jpg       \n",
            "  inflating: images/dogs19.jpg       \n",
            "  inflating: images/dogs2.jpg        \n",
            "  inflating: images/dogs20.jpg       \n",
            "  inflating: images/dogs21.jpg       \n",
            "  inflating: images/dogs22.jpg       \n",
            "  inflating: images/dogs23.jpg       \n",
            "  inflating: images/dogs24.jpg       \n",
            "  inflating: images/dogs25.jpg       \n",
            "  inflating: images/dogs26.jpg       \n",
            "  inflating: images/dogs27.jpg       \n",
            "  inflating: images/dogs28.jpg       \n",
            "  inflating: images/dogs29.jpg       \n",
            "  inflating: images/dogs3.jpg        \n",
            "  inflating: images/dogs30.jpg       \n",
            "  inflating: images/dogs31.jpg       \n",
            "  inflating: images/dogs32.jpg       \n",
            "  inflating: images/dogs33.jpg       \n",
            "  inflating: images/dogs34.jpg       \n",
            "  inflating: images/dogs35.jpg       \n",
            "  inflating: images/dogs36.jpg       \n",
            "  inflating: images/dogs37.jpg       \n",
            "  inflating: images/dogs38.jpg       \n",
            "  inflating: images/dogs39.jpg       \n",
            "  inflating: images/dogs4.jpg        \n",
            "  inflating: images/dogs5.jpg        \n",
            "  inflating: images/dogs6.jpg        \n",
            "  inflating: images/dogs7.jpg        \n",
            "  inflating: images/dogs8.jpg        \n",
            "  inflating: images/dogs9.jpg        \n",
            "  inflating: images/jaguar0.jpg      \n",
            "  inflating: images/jaguar1.jpg      \n",
            "  inflating: images/jaguar10.jpg     \n",
            "  inflating: images/jaguar11.jpg     \n",
            "  inflating: images/jaguar12.jpg     \n",
            "  inflating: images/jaguar13.jpg     \n",
            "  inflating: images/jaguar14.jpg     \n",
            "  inflating: images/jaguar15.jpg     \n",
            "  inflating: images/jaguar16.jpg     \n",
            "  inflating: images/jaguar17.jpg     \n",
            "  inflating: images/jaguar18.jpg     \n",
            "  inflating: images/jaguar19.jpg     \n",
            "  inflating: images/jaguar2.jpg      \n",
            "  inflating: images/jaguar20.jpg     \n",
            "  inflating: images/jaguar21.jpg     \n",
            "  inflating: images/jaguar22.jpg     \n",
            "  inflating: images/jaguar23.jpg     \n",
            "  inflating: images/jaguar24.jpg     \n",
            "  inflating: images/jaguar25.jpg     \n",
            "  inflating: images/jaguar26.jpg     \n",
            "  inflating: images/jaguar27.jpg     \n",
            "  inflating: images/jaguar28.jpg     \n",
            "  inflating: images/jaguar29.jpg     \n",
            "  inflating: images/jaguar3.jpg      \n",
            "  inflating: images/jaguar30.jpg     \n",
            "  inflating: images/jaguar31.jpg     \n",
            "  inflating: images/jaguar32.jpg     \n",
            "  inflating: images/jaguar33.jpg     \n",
            "  inflating: images/jaguar34.jpg     \n",
            "  inflating: images/jaguar35.jpg     \n",
            "  inflating: images/jaguar36.jpg     \n",
            "  inflating: images/jaguar37.jpg     \n",
            "  inflating: images/jaguar38.jpg     \n",
            "  inflating: images/jaguar39.jpg     \n",
            "  inflating: images/jaguar4.jpg      \n",
            "  inflating: images/jaguar5.jpg      \n",
            "  inflating: images/jaguar6.jpg      \n",
            "  inflating: images/jaguar7.jpg      \n",
            "  inflating: images/jaguar8.jpg      \n",
            "  inflating: images/jaguar9.jpg      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGiUpGYahatv"
      },
      "source": [
        "# VGG1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Zpm4ktHhBtJ",
        "outputId": "c780db9b-8b79-4c87-caba-894b1e679da9"
      },
      "source": [
        "\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "import os\n",
        "from os import listdir\n",
        "from numpy import asarray,save\n",
        "from numpy import save\n",
        "# define location of dataset\n",
        "folder = '/content/images/'\n",
        "\n",
        "photos, labels = list(), list()\n",
        "for file in listdir(folder):\n",
        "\toutput = 0.0\n",
        "\tif file.startswith('jaguar'):\n",
        "\t\toutput = 1.0\n",
        "\tphoto = load_img(folder + file, target_size=(200, 200))\n",
        "\tphoto = img_to_array(photo)\n",
        "\tphotos.append(photo)\n",
        "\tlabels.append(output)\n",
        "    \n",
        "photos = asarray(photos)\n",
        "labels = asarray(labels)\n",
        "print(photos.shape, labels.shape)\n",
        "\n",
        "from os import makedirs\n",
        "from os import listdir\n",
        "from shutil import copyfile\n",
        "from random import seed\n",
        "from random import random\n",
        "\n",
        "# create directories\n",
        "dirMain = '/content/images/'\n",
        "subdirs = ['train/', 'test/']\n",
        "for subdir in subdirs:\n",
        "\t# create label subdirectories\n",
        "\tlabeldirs = ['dogs/', 'jaguar/']\n",
        "\tfor labldir in labeldirs:\n",
        "\t\tnewdir = dirMain + subdir + labldir\n",
        "\t\tprint(newdir)\n",
        "\t\tos.makedirs(newdir, exist_ok=True)\n",
        "\n",
        "import random\n",
        "dogsImages = []\n",
        "jaguarImages = []\n",
        "\n",
        "for file in listdir(folder):\n",
        "\tif file.startswith('dogs'):\n",
        "\t\tdogsImages.append(file)\n",
        "\telif file.startswith('jaguar'):\n",
        "\t\tjaguarImages.append(file)\n",
        "\n",
        "testDogs = dogsImages[:len(dogsImages)//4]\n",
        "trainDogs = dogsImages[len(dogsImages)//4:]\n",
        "testJaguar = jaguarImages[:len(dogsImages)//4]\n",
        "trainJaguar = jaguarImages[len(dogsImages)//4:]\n",
        "\n",
        "srcDir = '/content/images/'\n",
        "dest = 'train/'\n",
        "for j in range(len(trainDogs)):\n",
        "\tsrc = srcDir + trainDogs[j]\n",
        "\tdst = dirMain + dest + 'dogs/' + trainDogs[j]\n",
        "\tcopyfile(src, dst)\n",
        "\tsrc = srcDir + trainJaguar[j]\n",
        "\tdst = dirMain + dest + 'jaguar/' + trainJaguar[j]\n",
        "\tcopyfile(src, dst)\n",
        "\n",
        "dest = 'test/'\n",
        "for j in range(len(testDogs)):\n",
        "\tsrc = srcDir + testDogs[j]\n",
        "\tdst = dirMain + dest + 'dogs/' + testDogs[j]\n",
        "\tcopyfile(src, dst)\n",
        "\tsrc = srcDir + testJaguar[j]\n",
        "\tdst = dirMain + dest + 'jaguar/' + testJaguar[j]\n",
        "\tcopyfile(src, dst)\n",
        "\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig('VGG1_plot.png')\n",
        "\tpyplot.close()\n",
        "\n",
        "\n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        " \n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig('VGG1_plot.png')\n",
        "\tpyplot.close()\n",
        " \n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\t# prepare iterators\n",
        "\ttrain_it = datagen.flow_from_directory('images/train/',class_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\ttest_it = datagen.flow_from_directory('images/test/',class_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\t# fit model\n",
        "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),validation_data=test_it, validation_steps=len(test_it), epochs=100, verbose=0)\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        " \n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80, 200, 200, 3) (80,)\n",
            "/content/images/train/dogs/\n",
            "/content/images/train/jaguar/\n",
            "/content/images/test/dogs/\n",
            "/content/images/test/jaguar/\n",
            "Found 60 images belonging to 2 classes.\n",
            "Found 20 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> 85.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K5DwHVKhVSD"
      },
      "source": [
        "# Data Augmentation VGG1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p_J-41chJaL",
        "outputId": "ecab7689-49fe-4218-a023-dbbeea387853"
      },
      "source": [
        "# baseline model with data augmentation for the dogs vs cats dataset\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig('dataAugmentationVGG1_plot.png')\n",
        "\tpyplot.close()\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# create data generators\n",
        "\ttrain_datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
        "\t\twidth_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "\ttest_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\t# prepare iterators\n",
        "\ttrain_it = train_datagen.flow_from_directory('./images/train/',\n",
        "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\ttest_it = test_datagen.flow_from_directory('./images/test/',\n",
        "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\t# fit model\n",
        "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
        "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=50, verbose=0)\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 60 images belonging to 2 classes.\n",
            "Found 20 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> 85.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4-UVDhHhNR8"
      },
      "source": [
        "# Transfer Learning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTZmd7_ThKiT",
        "outputId": "cb9ad1d5-53be-4ab0-ef3d-4be711bc8520"
      },
      "source": [
        "# vgg16 model used for transfer learning on the dogs and cats dataset\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# define cnn model\n",
        "def define_model():\n",
        "\t# load model\n",
        "\tmodel = VGG16(include_top=False, input_shape=(200, 200, 3))\n",
        "\t# mark loaded layers as not trainable\n",
        "\tfor layer in model.layers:\n",
        "\t\tlayer.trainable = False\n",
        "\t# add new classifier layers\n",
        "\tflat1 = Flatten()(model.layers[-1].output)\n",
        "\tclass1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
        "\toutput = Dense(1, activation='sigmoid')(class1)\n",
        "\t# define new model\n",
        "\tmodel = Model(inputs=model.inputs, outputs=output)\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig('TransferLearning_plot.png')\n",
        "\tpyplot.close()\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(featurewise_center=True)\n",
        "\t# specify imagenet mean values for centering\n",
        "\t# prepare iterator\n",
        "\ttrain_it = datagen.flow_from_directory('./images/train/',class_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\ttest_it = datagen.flow_from_directory('./images/test/',class_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\t# fit model\n",
        "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),validation_data=test_it, validation_steps=len(test_it), epochs=5, verbose=1)\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "Found 60 images belonging to 2 classes.\n",
            "Found 20 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 12s 12s/step - loss: 20.2525 - accuracy: 0.4833 - val_loss: 54.6580 - val_accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 443ms/step - loss: 54.5471 - accuracy: 0.5000 - val_loss: 4.7085e-19 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 1.1509e-06 - accuracy: 1.0000 - val_loss: 9.4536e-24 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 2.3513e-15 - accuracy: 1.0000 - val_loss: 6.9783e-17 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 4.4170e-24 - accuracy: 1.0000 - val_loss: 1.9184e-11 - val_accuracy: 1.0000\n",
            "> 100.000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}
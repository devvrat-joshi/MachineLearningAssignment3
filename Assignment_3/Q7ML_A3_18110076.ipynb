{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q7ML-A3-18110076.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "29hByVWNheij"
      },
      "source": [
        "! git clone https://github.com/devvrat-joshi/datafiles\n",
        "! unzip \"/content/datafiles/dataset.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGiUpGYahatv"
      },
      "source": [
        "# VGG1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Zpm4ktHhBtJ",
        "outputId": "b05ea83a-9b28-4079-afad-d03ec7a123ac"
      },
      "source": [
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "import os\n",
        "from os import listdir\n",
        "from numpy import asarray,save\n",
        "from numpy import save\n",
        "# define location of dataset\n",
        "folder = '/content/images/'\n",
        "\n",
        "photos, labels = list(), list()\n",
        "\n",
        "for file in listdir(folder):\n",
        "\toutput = 0.0\n",
        "\tif file.startswith('jaguar'):\n",
        "\t\toutput = 1.0\n",
        "\tphoto = load_img(folder + file, target_size=(200, 200))\n",
        "\tphoto = img_to_array(photo)\n",
        "\tphotos.append(photo)\n",
        "\tlabels.append(output)\n",
        "    \n",
        "photos = asarray(photos)\n",
        "labels = asarray(labels)\n",
        "print(photos.shape, labels.shape)\n",
        "\n",
        "from os import makedirs\n",
        "from os import listdir\n",
        "from shutil import copyfile\n",
        "from random import seed\n",
        "from random import random\n",
        "\n",
        "# create directories\n",
        "dataset_home = '/content/images/'\n",
        "subdirs = ['train/', 'test/']\n",
        "for subdir in subdirs:\n",
        "\t# create label subdirectories\n",
        "\tlabeldirs = ['dogs/', 'jaguar/']\n",
        "\tfor labldir in labeldirs:\n",
        "\t\tnewdir = dataset_home + subdir + labldir\n",
        "\t\tprint(newdir)\n",
        "\t\tos.makedirs(newdir, exist_ok=True)\n",
        "\n",
        "import random\n",
        "dogs_images = []\n",
        "jaguar_images = []\n",
        "\n",
        "for file in listdir(folder):\n",
        "\tif file.startswith('dogs'):\n",
        "\t\tdogs_images.append(file)\n",
        "\telif file.startswith('jaguar'):\n",
        "\t\tjaguar_images.append(file)\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(dogs_images) # shuffles the ordering of filenames (deterministic given the chosen seed)\n",
        "random.shuffle(jaguar_images) # shuffles the ordering of filenames (deterministic given the chosen seed)\n",
        "\n",
        "split_1 = int(0.25 * len(dogs_images))\n",
        "test_dogss = dogs_images[:split_1]\n",
        "train_dogss = dogs_images[split_1:]\n",
        "test_jaguars = jaguar_images[:split_1]\n",
        "train_jaguars = jaguar_images[split_1:]\n",
        "\n",
        "src_directory = '/content/images/'\n",
        "dst_dir = 'train/'\n",
        "for j in range(len(train_dogss)):\n",
        "\tsrc = src_directory + train_dogss[j]\n",
        "\tdst = dataset_home + dst_dir + 'dogs/' + train_dogss[j]\n",
        "\tcopyfile(src, dst)\n",
        "\tsrc = src_directory + train_jaguars[j]\n",
        "\tdst = dataset_home + dst_dir + 'jaguar/' + train_jaguars[j]\n",
        "\tcopyfile(src, dst)\n",
        "\n",
        "dst_dir = 'test/'\n",
        "for j in range(len(test_dogss)):\n",
        "\tsrc = src_directory + test_dogss[j]\n",
        "\tdst = dataset_home + dst_dir + 'dogs/' + test_dogss[j]\n",
        "\tcopyfile(src, dst)\n",
        "\tsrc = src_directory + test_jaguars[j]\n",
        "\tdst = dataset_home + dst_dir + 'jaguar/' + test_jaguars[j]\n",
        "\tcopyfile(src, dst)\n",
        "\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(filename + '_plot.png')\n",
        "\tpyplot.close()\n",
        "\n",
        "\n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        " \n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(filename + '_plot.png')\n",
        "\tpyplot.close()\n",
        " \n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\t# prepare iterators\n",
        "\ttrain_it = datagen.flow_from_directory('images/train/',class_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\ttest_it = datagen.flow_from_directory('images/test/',class_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\t# fit model\n",
        "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),validation_data=test_it, validation_steps=len(test_it), epochs=100, verbose=0)\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        " \n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80, 200, 200, 3) (80,)\n",
            "/content/images/train/dogs/\n",
            "/content/images/train/jaguar/\n",
            "/content/images/test/dogs/\n",
            "/content/images/test/jaguar/\n",
            "Found 60 images belonging to 2 classes.\n",
            "Found 20 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> 85.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K5DwHVKhVSD"
      },
      "source": [
        "# Data Augmentation VGG1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p_J-41chJaL",
        "outputId": "9d12d10c-f3b4-447c-fbb4-081d8de7c0a7"
      },
      "source": [
        "# baseline model with data augmentation for the dogs vs cats dataset\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(filename + '_plot.png')\n",
        "\tpyplot.close()\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# create data generators\n",
        "\ttrain_datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
        "\t\twidth_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "\ttest_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\t# prepare iterators\n",
        "\ttrain_it = train_datagen.flow_from_directory('./images/train/',\n",
        "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\ttest_it = test_datagen.flow_from_directory('./images/test/',\n",
        "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\t# fit model\n",
        "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
        "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=50, verbose=0)\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 60 images belonging to 2 classes.\n",
            "Found 20 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> 90.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4-UVDhHhNR8"
      },
      "source": [
        "# Transfer Learning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTZmd7_ThKiT",
        "outputId": "f13acc9e-2361-444a-c227-64820a6f9c12"
      },
      "source": [
        "# vgg16 model used for transfer learning on the dogs and cats dataset\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# define cnn model\n",
        "def define_model():\n",
        "\t# load model\n",
        "\tmodel = VGG16(include_top=False, input_shape=(200, 200, 3))\n",
        "\t# mark loaded layers as not trainable\n",
        "\tfor layer in model.layers:\n",
        "\t\tlayer.trainable = False\n",
        "\t# add new classifier layers\n",
        "\tflat1 = Flatten()(model.layers[-1].output)\n",
        "\tclass1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
        "\toutput = Dense(1, activation='sigmoid')(class1)\n",
        "\t# define new model\n",
        "\tmodel = Model(inputs=model.inputs, outputs=output)\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(filename + '_plot.png')\n",
        "\tpyplot.close()\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(featurewise_center=True)\n",
        "\t# specify imagenet mean values for centering\n",
        "\t# prepare iterator\n",
        "\ttrain_it = datagen.flow_from_directory('./images/train/',class_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\ttest_it = datagen.flow_from_directory('./images/test/',class_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\t# fit model\n",
        "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),validation_data=test_it, validation_steps=len(test_it), epochs=5, verbose=1)\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "Found 60 images belonging to 2 classes.\n",
            "Found 20 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 13s 13s/step - loss: 5.5355 - accuracy: 0.5667 - val_loss: 1.1804e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 459ms/step - loss: 1.0630e-21 - accuracy: 1.0000 - val_loss: 1.9870e-08 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 451ms/step - loss: 3.0397e-37 - accuracy: 1.0000 - val_loss: 5.8345e-10 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5609e-11 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 441ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.2033e-13 - val_accuracy: 1.0000\n",
            "> 100.000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}